{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHQ7iuvZKZp/k+ALBa5Huc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataLama/triton-tutorials/blob/main/tutorials/basic/2_vector_add.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv5GSZ_7Ldzf",
        "outputId": "52242bc5-3e5b-49b4-f0a8-d065f6036374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.2.1+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision\n",
            "Name: triton\n",
            "Version: 2.2.0\n",
            "Summary: A language and compiler for custom Deep Learning operations\n",
            "Home-page: https://github.com/openai/triton/\n",
            "Author: Philippe Tillet\n",
            "Author-email: phil@openai.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock\n",
            "Required-by: torch\n"
          ]
        }
      ],
      "source": [
        "!pip show torch\n",
        "!pip show triton"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GQS85MTuMkaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `tl.store`\n",
        "\n",
        "Store a tensor of data into memory locations defined by pointer:\n",
        "    \n",
        "(1) pointer could be a single element pointer, then a scalar will be stored\n",
        "\n",
        "- `mask` must be scalar too\n",
        "- `boundary_check` and `padding_option` must be empty\n",
        "    \n",
        "(2) pointer could be element-wise tensor of pointers, in which case:\n",
        "\n",
        "- `mask` is implicitly broadcast to `pointer.shape`\n",
        "- `boundary_check` must be empty\n",
        "    \n",
        "(3) or pointer could be a block pointer defined by make_block_ptr, in which case:\n",
        "\n",
        "- `mask` must be None\n",
        "- `boundary_check` can be specified to control the behavior of out-of-bound access value is implicitly broadcast to pointer.shape and typecast to pointer.dtype.element_ty."
      ],
      "metadata": {
        "id": "COoZ6QDNi8hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from typing import Dict\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "@triton.jit\n",
        "def add_kernel(\n",
        "    # python에서는 tensor를 넘겨주는데, kernel에서는 해당 tensor의 포인터를 갖고오는 듯?\n",
        "    x_ptr: torch.Tensor,\n",
        "    y_ptr: torch.Tensor,\n",
        "    z_ptr: torch.Tensor,\n",
        "    size: int,\n",
        "    block_size: tl.constexpr,\n",
        "  ):\n",
        "  # define offsets\n",
        "  pid = tl.program_id(0) # 3D grid에서 해당 axis의 program_id.\n",
        "  offsets = tl.arange(0, block_size) + pid * block_size # pid를 기준으로 정의된 block_size만큼 offset 생성.\n",
        "  mask = offsets < size # offset의 크기가 tensor의 사이즈보다 클 경우 마스킹처리\n",
        "\n",
        "  # load tensor from DRAM\n",
        "  x = tl.load(x_ptr + offsets, mask)\n",
        "  y = tl.load(y_ptr + offsets, mask)\n",
        "\n",
        "  z = x + y # add on gpu\n",
        "\n",
        "  # export tensor to DRAM.\n",
        "  tl.store(z_ptr + offsets, z, mask)\n",
        "\n",
        "def add (x:torch.Tensor, y:torch.Tensor):\n",
        "  z = torch.empty_like(x, device='cuda')\n",
        "  size = z.numel() # number of element in tensor.\n",
        "\n",
        "  def grid(meta:Dict):\n",
        "    # meta는 triton kernel이 input으로 받는 kwags ...\n",
        "    return (triton.cdiv(size, meta[\"block_size\"]),)\n",
        "\n",
        "  add_kernel[grid](x, y, z , size, 2**10)\n",
        "\n",
        "  return z\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  size = 2 ** 16\n",
        "  x = torch.randn(size, device=\"cuda\")\n",
        "  y = torch.randn(size, device=\"cuda\")\n",
        "\n",
        "  a = add(x, y) # triton\n",
        "  b = x + y # torch\n",
        "\n",
        "  print(sum(b - a))\n",
        "  assert torch.allclose(a, b, atol=1e-2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA07XyqbMmIf",
        "outputId": "e03d56a3-ace2-408f-cfe9-a6b494cd806b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S_3pd96bxQ6",
        "outputId": "8aaa0562-88fb-4b88-d15d-814761d58bad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0., device='cuda:0')\n",
            "CPU times: user 26 ms, sys: 2.77 ms, total: 28.8 ms\n",
            "Wall time: 3.02 s\n"
          ]
        }
      ]
    }
  ]
}