{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsLMuYN3Y84F3lKS1sgAtr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataLama/triton-tutorials/blob/main/tutorials/basic/3_matrix_multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsUYzsL2jsO3",
        "outputId": "222c6a73-c998-4ddb-da6d-186269aa5111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.2.1+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision\n",
            "Name: triton\n",
            "Version: 2.2.0\n",
            "Summary: A language and compiler for custom Deep Learning operations\n",
            "Home-page: https://github.com/openai/triton/\n",
            "Author: Philippe Tillet\n",
            "Author-email: phil@openai.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock\n",
            "Required-by: torch\n"
          ]
        }
      ],
      "source": [
        "!pip show torch\n",
        "!pip show triton"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CH96BJZVjyHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from typing import Dict\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "@triton.jit\n",
        "def matmul_kernel(\n",
        "    x_ptr: torch.Tensor,\n",
        "    y_ptr: torch.Tensor,\n",
        "    z_ptr: torch.Tensor,\n",
        "    m: int,\n",
        "    n: int,\n",
        "    k: int,\n",
        "    m_block_size: tl.constexpr,\n",
        "    n_block_size: tl.constexpr,\n",
        "    k_block_size: tl.constexpr,\n",
        "):\n",
        "  # let n_size = 16, n_block_size = 2\n",
        "  # pid in {0, 1, 2, 3, ..., 64}\n",
        "  # (m_block, n_block) in {(0, 0), (0, 1), (0, 2), (0, 3), ... , (7, 7)}\n",
        "  pid = tl.program_id(0)\n",
        "  num_n_blocks = tl.cdiv(n, n_block_size) # n의 축으로 존재하는 모든 block의 갯수 8개\n",
        "  m_block = pid // num_n_blocks\n",
        "  n_block = pid % num_n_blocks\n",
        "\n",
        "  # (m_block, n_block)을 시작점으로 m_block_size, n_block_size 만큼의 텐서 공간을 확보.. 값을 저장하는...\n",
        "  # z가 tensor z의 부분 텐서일 때,  z_(m_block, n_block)으로 표현 가능.\n",
        "  # z_(m_block, n_block)를 계산하기 위한 부분은 (m_block, k) by (k, n_block)으로 표현 가능함.\n",
        "  m_offsets = tl.arange(0, m_block_size) + m_block * m_block_size\n",
        "  n_offsets = tl.arange(0, n_block_size) + n_block * n_block_size\n",
        "  k_offsets = tl.arange(0, k_block_size) # k_offsets는 (m_block, k) by (k, n_block) 이 두 행렬을 바로 곱하는게 아니라 이걸 또 부분행렬로 쪼개서 iteration돌면서 계산하는데, 그때의 크기.\n",
        "\n",
        "  # x, y, z 행렬의 포인터를 정의\n",
        "  x_ptrs = x_ptr + m_offsets[:, None] * k + k_offsets[None, :]\n",
        "  y_ptrs = y_ptr + k_offsets[:, None] * n + n_offsets[None, :]\n",
        "  z_ptrs = z_ptr + m_offsets[:, None] * n + n_offsets[None, :]\n",
        "\n",
        "  # z값을 0으로 초기화\n",
        "  z = tl.zeros((m_block_size, n_block_size), dtype=tl.float32)\n",
        "\n",
        "  for _ in range(0, k, k_block_size):\n",
        "    # x, y를 로드\n",
        "    x_sub = tl.load(x_ptrs)\n",
        "    y_sub = tl.load(y_ptrs)\n",
        "\n",
        "    # x_sub와 y_sub를 곱하여 z에 누적.\n",
        "    z += tl.dot(x_sub, y_sub, allow_tf32=False)\n",
        "\n",
        "    # next pointer로 이동\n",
        "    x_ptrs += k_block_size\n",
        "    y_ptrs += k_block_size * n\n",
        "\n",
        "  # z포인터에 z값 저장\n",
        "  tl.store(z_ptrs, z)\n",
        "\n",
        "def matmul(x, y):\n",
        "  m, k = x.shape\n",
        "  _, n = y.shape\n",
        "  z = torch.empty(m, n, device='cuda')\n",
        "\n",
        "  def grid(meta):\n",
        "    # m = 16, m_block_size = 2\n",
        "    # n = 16, n_block_size = 2\n",
        "    # grid의 x축 방향으로 64개 블록을 align.\n",
        "    return (triton.cdiv(m, meta['m_block_size']) * triton.cdiv(n, meta['n_block_size']), )\n",
        "\n",
        "\n",
        "  matmul_kernel[grid](\n",
        "      x, y, z,\n",
        "      m, k, n,\n",
        "      m, k, n,\n",
        "  )\n",
        "\n",
        "  return z\n",
        "\n",
        "def main():\n",
        "  x = torch.randn(16, 16, device=\"cuda\")\n",
        "  y = torch.randn(16, 16, device=\"cuda\")\n",
        "\n",
        "  a = matmul(x, y)\n",
        "  b = torch.matmul(x, y)\n",
        "\n",
        "  assert torch.allclose(a, b)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgNGQDGljzbT",
        "outputId": "be5506f6-680a-4ca0-b1d4-da0fa4a04a93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temperal하게 allclose에러를 뱉는다.\n",
        "!python main.py"
      ],
      "metadata": {
        "id": "DSQVYZYFlMWv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "경계 검사를 도입하여, 다양한 크기의 행렬에 대한 연산을 구현하면 좋을듯?\n",
        "\n",
        "https://github.com/openai/triton/blob/main/python/tutorials/03-matrix-multiplication.py"
      ],
      "metadata": {
        "id": "9cuEvOW_zazn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vAmMUxOGzt_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}